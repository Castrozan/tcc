<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang xml:lang>
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>AGENTE CONVERSACIONAL PARA INTERAÇÃO APRIMORADA EM SISTEMAS</title>
  <style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}

ul.task-list[class]{list-style: none;}
ul.task-list li input[type="checkbox"] {
font-size: inherit;
width: 0.8em;
margin: 0 0.8em 0.2em -1.6em;
vertical-align: middle;
}
.display.math{display: block; text-align: center; margin: 0.5rem auto;}
</style>
  <style type="text/css">
html {
font-size: 100%;
overflow-y: scroll;
-webkit-text-size-adjust: 100%;
-ms-text-size-adjust: 100%;
}
body {
color: #444;
font-family: Georgia, Palatino, "Palatino Linotype", Times, "Times New Roman",
serif;
font-size: 12px;
line-height: 1.7;
padding: 1em;
margin: auto;
max-width: 42em;
background: #fefefe;
}
a {
color: #0645ad;
text-decoration: none;
}
a:visited {
color: #0b0080;
}
a:hover {
color: #06e;
}
a:active {
color: #faa700;
}
a:focus {
outline: thin dotted;
}
*::-moz-selection {
background: rgba(255, 255, 0, 0.3);
color: #000;
}
*::selection {
background: rgba(255, 255, 0, 0.3);
color: #000;
}
a::-moz-selection {
background: rgba(255, 255, 0, 0.3);
color: #0645ad;
}
a::selection {
background: rgba(255, 255, 0, 0.3);
color: #0645ad;
}
p {
margin: 1em 0;
}
img {
max-width: 100%;
}
h1,
h2,
h3,
h4,
h5,
h6 {
color: #111;
line-height: 125%;
margin-top: 2em;
font-weight: normal;
}
h4,
h5,
h6 {
font-weight: bold;
}
h1 {
font-size: 2.5em;
}
h2 {
font-size: 2em;
}
h3 {
font-size: 1.5em;
}
h4 {
font-size: 1.2em;
}
h5 {
font-size: 1em;
}
h6 {
font-size: 0.9em;
}
blockquote {
color: #666666;
margin: 0;
padding-left: 3em;
border-left: 0.5em #eee solid;
}
hr {
display: block;
height: 2px;
border: 0;
border-top: 1px solid #aaa;
border-bottom: 1px solid #eee;
margin: 1em 0;
padding: 0;
}
pre,
code,
kbd,
samp {
color: #000;
font-family: monospace, monospace;
_font-family: "courier new", monospace;
font-size: 0.98em;
}
pre {
white-space: pre;
white-space: pre-wrap;
word-wrap: break-word;
}
b,
strong {
font-weight: bold;
}
dfn {
font-style: italic;
}
ins {
background: #ff9;
color: #000;
text-decoration: none;
}
mark {
background: #ff0;
color: #000;
font-style: italic;
font-weight: bold;
}
sub,
sup {
font-size: 75%;
line-height: 0;
position: relative;
vertical-align: baseline;
}
sup {
top: -0.5em;
}
sub {
bottom: -0.25em;
}
ul,
ol {
margin: 1em 0;
padding: 0 0 0 2em;
}
li p:last-child {
margin-bottom: 0;
}
ul ul,
ol ol {
margin: 0.3em 0;
}
dl {
margin-bottom: 1em;
}
dt {
font-weight: bold;
margin-bottom: 0.8em;
}
dd {
margin: 0 0 0.8em 2em;
}
dd:last-child {
margin-bottom: 0;
}
img {
border: 0;
-ms-interpolation-mode: bicubic;
vertical-align: middle;
}
figure {
display: block;
text-align: center;
margin: 1em 0;
}
figure img {
border: none;
margin: 0 auto;
}
figcaption {
font-size: 0.8em;
font-style: italic;
margin: 0 0 0.8em;
}
table {
margin-bottom: 2em;
border-bottom: 1px solid #ddd;
border-right: 1px solid #ddd;
border-spacing: 0;
border-collapse: collapse;
}
table th {
padding: 0.2em 1em;
background-color: #eee;
border-top: 1px solid #ddd;
border-left: 1px solid #ddd;
}
table td {
padding: 0.2em 1em;
border-top: 1px solid #ddd;
border-left: 1px solid #ddd;
vertical-align: top;
}
.author {
font-size: 1.2em;
text-align: center;
}
@media only screen and (min-width: 480px) {
body {
font-size: 14px;
}
}
@media only screen and (min-width: 768px) {
body {
font-size: 16px;
}
}
@media print {
* {
background: transparent !important;
color: black !important;
filter: none !important;
-ms-filter: none !important;
}
body {
font-size: 12pt;
max-width: 100%;
}
a,
a:visited {
text-decoration: underline;
}
hr {
height: 1px;
border: 0;
border-bottom: 1px solid black;
}
a[href]:after {
content: " (" attr(href) ")";
}
abbr[title]:after {
content: " (" attr(title) ")";
}
.ir a:after,
a[href^="javascript:"]:after,
a[href^="#"]:after {
content: "";
}
pre,
blockquote {
border: 1px solid #999;
padding-right: 1em;
page-break-inside: avoid;
}
tr,
img {
page-break-inside: avoid;
}
img {
max-width: 100% !important;
}
@page :left {
margin: 15mm 20mm 15mm 10mm;
}
@page :right {
margin: 15mm 10mm 15mm 20mm;
}
p,
h2,
h3 {
orphans: 3;
widows: 3;
}
h2,
h3 {
page-break-after: avoid;
}
}
</style>
</head>
<body>
<header id="title-block-header">
<h1 class="title"><strong>AGENTE CONVERSACIONAL PARA INTERAÇÃO
APRIMORADA EM SISTEMAS</strong></h1>
</header>
<h3 id="artigo-em-produção---checklist-de-produção">Artigo em produção -
Checklist de produção</h3>
<ul class="task-list">
<li><label><input type="checkbox"></input>Edição do artigo</label>
<ul class="task-list">
<li><label><input type="checkbox"></input>Aplicar ABNT</label></li>
<li><label><input type="checkbox"></input>Aplicar formatação da
SATC</label></li>
</ul></li>
<li><label><input type="checkbox"></input>Escrita</label>
<ul class="task-list">
<li><label><input type="checkbox"></input>Resumo</label>
<ul class="task-list">
<li><label><input type="checkbox" checked></input>Esqueleto</label></li>
<li><label><input type="checkbox"></input>Revisão após finalizar o
artigo</label></li>
</ul></li>
<li><label><input type="checkbox" checked></input>Introdução (preciso de
umas referências)</label></li>
<li><label><input type="checkbox"></input>Material e métodos</label>
<ul class="task-list">
<li><label><input type="checkbox" checked></input>Abordagem
geral</label></li>
<li><label><input type="checkbox"></input>Procedimento experimental de cada
alternativa</label></li>
</ul></li>
<li><label><input type="checkbox"></input>Resultados e discussão</label></li>
<li><label><input type="checkbox"></input>Considerações finais</label></li>
<li><label><input type="checkbox"></input>Referências</label>
<ul class="task-list">
<li><label><input type="checkbox"></input>Formatar ABNT</label></li>
</ul></li>
</ul></li>
</ul>
<p><strong>Lucas de Castro Zanoni</strong><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p><strong>Thyerri Fernandes Mezzari</strong><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>Resumo: Este trabalho apresenta o desenvolvimento de um agente
conversacional baseado em inteligência artificial para aprimorar a
interação entre usuários e sistemas. Utilizando técnicas avançadas de
processamento de linguagem natural, o agente proposto visa simplificar a
comunicação em interfaces complexas, proporcionando uma experiência
digital unificada e adaptável às necessidades dos usuários. A
metodologia inclui o desenvolvimento, implementação e avaliação do
agente em ambientes reais de uso. Os resultados demonstram que a solução
proposta contribui significativamente para a melhoria da acessibilidade
e usabilidade dos sistemas, reduzindo barreiras de interação e
promovendo uma comunicação mais fluida e intuitiva.</p>
<p><strong>Palavras-chaves:</strong> agente conversacional, interação,
sistema, inteligência artificial.</p>
<h1 id="introdução">1 INTRODUÇÃO</h1>
<p>A evolução das interfaces de usuário tem gerado uma diversidade de
padrões de design e usabilidade, resultando frequentemente em barreiras
para a plena acessibilidade e interação dos usuários com os sistemas
digitais. Com o aumento da complexidade do frontend e a multiplicidade
de paradigmas de interação, muitos usuários enfrentam dificuldades
significativas para utilizar efetivamente as funcionalidades oferecidas
pelos sistemas computacionais modernos <span class="citation" data-cites="RAPP201849">[@RAPP201849]</span> <span class="citation" data-cites="Kocaballi2019">[@Kocaballi2019]</span>.</p>
<p>Nesse cenário, os agentes conversacionais baseados em inteligência
artificial emergem como uma alternativa promissora para simplificar a
comunicação entre humanos e máquinas, oferecendo uma camada
intermediária de interação que pode traduzir comandos em linguagem
natural para ações específicas no sistema.</p>
<p>Estudos recentes têm demonstrado que agentes conversacionais podem
aprimorar significativamente a experiência do usuário ao simplificar
interações com sistemas complexos <span class="citation" data-cites="fast2017irisconversationalagentcomplex">[@fast2017irisconversationalagentcomplex]</span>.
Além disso, a implementação de interfaces baseadas em linguagem natural
tem mostrado potencial para melhorar a usabilidade em contextos
domésticos e inteligentes, reduzindo o tempo e o esforço necessários
para completar tarefas complexas <span class="citation" data-cites="Guo2024Doppelganger">[@Guo2024Doppelganger]</span>. Ademais,
tais interfaces oferecem vantagens consideráveis em termos de
acessibilidade, permitindo uma comunicação mais inclusiva e adaptável a
usuários com diferentes necessidades especiais <span class="citation" data-cites="Lister2020AccessibleCU">[@Lister2020AccessibleCU]</span>
<span class="citation" data-cites="Deng2023AMA">[@Deng2023AMA]</span>.</p>
<p>A problemática central desta pesquisa reside na questão: de que forma
um agente conversacional baseado em IA pode potencializar a interação
entre usuários e sistemas, promovendo uma comunicação fluida mesmo em
ambientes com interfaces complexas? Essa pergunta reflete a necessidade
crescente de soluções que democratizem o acesso à tecnologia, reduzindo
a curva de aprendizado necessária para a utilização de sistemas
especializados e tornando-os mais acessíveis para diferentes perfis de
usuários.</p>
<p>Adicionalmente, trabalhos recentes indicam que avanços na arquitetura
de modelos de IA, como o uso de transformers sem camadas de
normalização, podem influenciar positivamente o desempenho e a
eficiência desses agentes <span class="citation" data-cites="Zhu2025DyT">[@Zhu2025DyT]</span>.</p>
<p>A relevância deste estudo evidencia-se pelo potencial transformador
que os agentes conversacionais representam para a área de interação
humano-computador. Ao implementar um sistema intermediário capaz de
interpretar linguagem natural e traduzi-la em ações específicas dentro
de um sistema, cria-se uma ponte que permite aos usuários interagir de
forma mais intuitiva e natural com as tecnologias digitais. Esta
abordagem tem o potencial de mitigar as barreiras impostas por
interfaces complexas, contribuindo para uma maior inclusão digital e
para a melhoria da experiência do usuário em diversos contextos de
aplicação.</p>
<!-- ## Abordagens de Integração para Análise

### 1. Conexão Direta com Banco de Dados
- [ ] Análise de Vantagens:
  - Acesso direto aos dados brutos
  - Menor latência na recuperação de dados
  - Sem necessidade de camadas API intermediárias
  - Controle completo sobre padrões de acesso a dados
- [ ] Análise de Desvantagens:
  - Preocupações com segurança no acesso direto ao BD
  - Necessidade de lidar com múltiplos tipos de BD
  - Geração complexa de SQL
  - Requer compreensão profunda do esquema
  - Alta manutenção quando o esquema do BD muda

### 2. Integração via Plugin ORM
- [ ] Análise de Vantagens:
  - Aproveita a lógica da aplicação existente
  - Melhor segurança através das camadas do ORM
  - Manutenção mais fácil (segue atualizações da aplicação)
  - Uso mais eficiente de recursos
- [ ] Análise de Desvantagens:
  - Específico para linguagem/framework
  - Requer modificação do código existente
  - Limitado às capacidades do ORM
  - Maior complexidade de implementação para desenvolvedores

### 3. Integração via API/Swagger
- [ ] Análise de Vantagens:
  - Utiliza infraestrutura de API existente
  - Melhor segurança (camadas de autenticação existentes)
  - Agnóstico quanto a linguagem/framework
  - Mais fácil de implementar em sistemas existentes
- [ ] Análise de Desvantagens:
  - Maior latência (requisições HTTP)
  - Sobrecarga de rede
  - Depende da disponibilidade da API
  - Pode requerer múltiplas requisições para operações complexas

### 4. Model Context Protocol (MCP)
- [ ] Análise de Vantagens:
  - Forma padronizada de definir interações com ferramentas
  - Flexível e extensível
  - Agnóstico quanto a linguagem
  - Clara separação de responsabilidades
- [ ] Análise de Desvantagens:
  - Necessita geração dinâmica de servidor
  - Infraestrutura adicional necessária
  - Tecnologia mais recente com menos suporte da comunidade
  - Implementação complexa para ferramentas dinâmicas

## Estrutura de Pesquisa

### 1. Fundamentação Teórica
- [ ] Revisão de padrões existentes de integração com LLMs
- [ ] Análise de arquiteturas de integração de sistemas
- [ ] Considerações de segurança em integrações com IA
- [ ] Métricas e considerações de desempenho

### 2. Análise de Implementação
- [ ] Para cada abordagem:
  - [ ] Design arquitetural
  - [ ] Considerações de segurança
  - [ ] Implicações de desempenho
  - [ ] Complexidade de implementação
  - [ ] Requisitos de manutenção
  - [ ] Aspectos de escalabilidade

### 3. Prova de Conceito
- [ ] Implementação em pequena escala de cada abordagem
- [ ] Cenário de teste padronizado
- [ ] Coleta de métricas de desempenho
- [ ] Análise de segurança
- [ ] Avaliação da experiência do usuário

### 4. Critérios de Avaliação
- [ ] Métricas de desempenho
- [ ] Avaliação de segurança
- [ ] Complexidade de implementação
- [ ] Sobrecarga de manutenção
- [ ] Potencial de escalabilidade
- [ ] Experiência do usuário
- [ ] Esforço de integração

### 5. Framework de Comparação
- [ ] Metodologia de comparação padronizada
- [ ] Métricas quantitativas
- [ ] Análise qualitativa
- [ ] Considerações específicas de casos de uso -->
<h1 id="procedimento-experimental">2 PROCEDIMENTO EXPERIMENTAL</h1>
<p>Este trabalho adota uma abordagem metodológica estruturada em
múltiplas etapas para investigar e avaliar diferentes métodos de
integração entre agentes conversacionais baseados em LLMs (Large
Language Models) e sistemas computacionais. A pesquisa se desenvolve
através de uma análise comparativa de quatro abordagens distintas de
integração, cada uma com suas características, vantagens e limitações
específicas.</p>
<p>O processo investigativo inicia-se com uma revisão sistemática da
literatura sobre integrações entre LLMs e sistemas, estabelecendo uma
base teórica sólida para a análise subsequente. Em seguida, são
exploradas quatro abordagens principais de integração: (1) conexão
direta com banco de dados, permitindo consultas e manipulações diretas;
(2) integração via plugins ORM, facilitando o acesso através de camadas
de abstração existentes; (3) integração via API/Swagger, utilizando
interfaces padronizadas de comunicação; e (4) integração via Model
Context Protocol (MCP), explorando um paradigma emergente de comunicação
entre LLMs e sistemas.</p>
<p>Para cada abordagem, será desenvolvida uma prova de conceito que
demonstre sua viabilidade técnica e permita uma avaliação objetiva de
seus aspectos funcionais e não-funcionais. A avaliação seguirá critérios
predefinidos, incluindo desempenho, segurança, facilidade de
implementação, manutenibilidade e experiência do usuário. Os resultados
serão documentados e analisados de forma sistemática, permitindo uma
comparação objetiva entre as diferentes abordagens.</p>
<h2 id="materiais">2.1 MATERIAIS</h2>
<!-- Esta seção deve indicar os recursos utilizados para realizar a
pesquisa.  Deve, portanto, apresentar os materiais utilizados na
pesquisa o tamanho da amostra e como ela foi determinada. -->
<p>Para garantir a rigorosidade científica e a reprodutibilidade dos
experimentos conduzidos neste estudo, é essencial uma seleção criteriosa
dos materiais e ferramentas utilizados. Esta seção detalha os recursos
específicos empregados na condução desta pesquisa, justificando sua
escolha baseada na eficiência, popularidade, robustez e aplicabilidade
prática dentro do contexto dos agentes conversacionais e integração de
sistemas.</p>
<h3 id="node.js-para-desenvolvimento-das-provas-de-conceito">Node.js
para Desenvolvimento das Provas de Conceito</h3>
<p>Node.js foi escolhido como plataforma principal para o
desenvolvimento das provas de conceito devido à sua comprovada eficácia
na integração de sistemas baseados em inteligência artificial (IA),
especialmente com agentes conversacionais e Large Language Models
(LLMs). A plataforma é amplamente adotada devido à sua arquitetura
orientada a eventos e capacidade de gerenciar eficientemente múltiplas
conexões simultâneas, essencial para aplicações que exigem respostas
rápidas em tempo real <span class="citation" data-cites="cherednichenko:hal-04545073">[@cherednichenko:hal-04545073]</span>.</p>
<p>O Hugging Face fornece bibliotecas JavaScript específicas compatíveis
com Node.js, como o <code>@huggingface/inference</code>, permitindo
acesso direto a mais de 100 mil modelos pré-treinados com suporte a
TypeScript. Isso simplifica significativamente a integração com IA,
destacando a robustez técnica e facilidade de adoção do Node.js em
aplicações modernas <span class="citation" data-cites="HuggingFace2024">[@HuggingFace2024]</span>.</p>
<p>Grandes empresas também reforçam a relevância de Node.js ao
disponibilizarem SDKs específicos, como o da IBM para o Watsonx, lançado
em 2023. Este SDK facilita o uso direto de modelos generativos robustos
da IBM em aplicações Node.js, destacando sua relevância estratégica no
ambiente empresarial <span class="citation" data-cites="IBM2023WatsonxSDK">[@IBM2023WatsonxSDK]</span>.</p>
<p>Adicionalmente, a documentação oficial do Node.js ressalta sua
capacidade superior de lidar com streaming de dados através de streams e
pipelines. Essa funcionalidade permite transmitir resultados
incrementais de IA aos clientes com baixa latência, tornando-o ideal
para chatbots e serviços em tempo real que dependem de respostas
imediatas <span class="citation" data-cites="Nodejs2024Docs">[@Nodejs2024Docs]</span>.</p>
<p>Por fim, relatórios da Red Hat destacam que o uso eficiente da
arquitetura assíncrona do Node.js possibilita a criação de agentes
baseados em LLMs com alta performance e escalabilidade. Isso garante um
gerenciamento eficiente de múltiplas operações paralelas, essencial para
aplicações intensivas em IA e integração com APIs externas <span class="citation" data-cites="RedHat2024LLMNode">[@RedHat2024LLMNode]</span>.</p>
<h3 id="testes-end-to-end-e2e">Testes End-to-End (e2e)</h3>
<p>O Framework de Gerenciamento de Riscos de IA do NIST <span class="citation" data-cites="oprea2023adversarial">[@oprea2023adversarial]</span> destaca
a importância de avaliar o desempenho de sistemas de IA de forma
abrangente, defendendo que testes de integração devem avaliar os
sistemas de ponta a ponta para identificar erros de integração e
garantir a precisão das respostas em cenários realistas. Testes
rigorosos como esses não apenas identificam problemas de integração, mas
também asseguram às partes interessadas que o sistema se comporta
conforme o esperado em condições do mundo real.</p>
<p>A injeção de prompt representa um risco significativo em implantações
de LLMs em nosso cenário, no qual o modelo possui acesso a dados e
sistemas potencialmente críticos, incluindo, ocasionalmente, conexões
diretas com dados brutos de banco de dados. O guia de riscos da OWASP
<span class="citation" data-cites="john2025owasp">[@john2025owasp]</span> classifica a injeção
de prompt como uma ameaça crítica à segurança, destacando a necessidade
de procedimentos de teste rigorosos para garantir que agentes
conversacionais baseados em LLMs não revelem inadvertidamente dados
sensíveis ou contornem restrições do sistema quando expostos a entradas
maliciosas. Recentemente, <span class="citation" data-cites="wu2023defending">[@wu2023defending]</span> demonstraram que
ataques de jailbreak — um tipo avançado de injeção de prompt — podem
burlar as salvaguardas éticas de modelos como o ChatGPT em até 67% dos
casos, gerando conteúdos prejudiciais como extorsão e desinformação.</p>
<p>Com isso em mente, o uso de testes E2E pode ser utilizado para
avaliar a resiliência da implementação ao simular entradas adversárias,
processo conhecido como red teaming. Segundo <span class="citation" data-cites="inie2025summon">[@inie2025summon]</span>, o red teaming
desafia sistematicamente sistemas de IA com prompts adversários
projetados para testar seus limites e mecanismos de segurança. Ao
encapsular consultas do usuário com lembretes de responsabilidade ética
(e.g., “Você deve ser um ChatGPT responsável”), o método reduziu a taxa
de sucesso de jailbreaks para 19%, mantendo a funcionalidade padrão do
modelo — um resultado validado através de testes E2E em 540 cenários
adversarialmente projetados <span class="citation" data-cites="wu2023defending">[@wu2023defending]</span>.</p>
<p>Testes de robustez, como os propostos pelo framework CheckList <span class="citation" data-cites="ribeiro2020beyond">[@ribeiro2020beyond]</span>, complementam
ainda mais os testes E2E ao variar sistematicamente as entradas — como
paráfrases, negações ou ruído — para avaliar a consistência e a precisão
do modelo em diferentes cenários. Esse método garante que sistemas
baseados em LLM lidem de forma confiável com interações diversas dos
usuários, atributo essencial para manter a confiança dos usuários e a
estabilidade operacional, especialmente em aplicações críticas de
negócios ou voltadas à segurança.</p>
<h3 id="modelos-de-linguagem-de-grande-escala-llms">Modelos de Linguagem
de Grande Escala (LLMs)</h3>
<p>Os modelos de linguagem (LLMs), incluindo tecnologias como OpenAI
GPT, Anthropic e modelos disponibilizados pela Google, são essenciais
neste estudo devido à sua capacidade de interpretar e gerar linguagem
natural de forma avançada e eficaz. Estes modelos foram selecionados por
sua performance comprovada e ampla adoção em pesquisas acadêmicas e no
mercado corporativo, proporcionando um sólido embasamento para as
funcionalidades de interação do agente conversacional.</p>
<h3 id="ferramentas-específicas-de-integração">Ferramentas Específicas
de Integração</h3>
<p>A pesquisa investigou quatro abordagens distintas para a integração
dos agentes conversacionais com sistemas computacionais, utilizando
ferramentas específicas para cada uma:</p>
<ul>
<li><p><strong>PostgreSQL para Conexão Direta com Banco de
Dados:</strong> Selecionado por sua robustez, estabilidade e desempenho
em ambientes produtivos, o PostgreSQL permite consultas diretas aos
dados brutos, oferecendo uma abordagem direta e eficiente.</p></li>
<li><p><strong>Sequelize para Integração via ORM:</strong> Este ORM
proporciona uma camada adicional de segurança e abstração, facilitando a
manutenção e a adaptação da integração ao esquema de dados existente,
reduzindo complexidade técnica e aumentando a eficiência
operacional.</p></li>
<li><p><strong>OpenAPI para Integração via API/Swagger:</strong> A
utilização da especificação OpenAPI oferece uma interface padronizada e
consistente para comunicação com serviços existentes através de APIs,
garantindo interoperabilidade e simplificando o
desenvolvimento.</p></li>
<li><p><strong>Model Context Protocol (MCP):</strong> Este protocolo
emergente foi explorado devido à sua flexibilidade e capacidade de
fornecer uma estrutura padronizada para interação com ferramentas,
essencial para futuras expansões e integrações com sistemas dinâmicos e
complexos.</p></li>
</ul>
<h3 id="importância-e-relevância-dos-materiais-escolhidos">Importância e
Relevância dos Materiais Escolhidos</h3>
<p>Os materiais escolhidos destacam-se não apenas pela capacidade
técnica individual, mas também pela complementaridade entre si. Essa
abordagem assegura que a pesquisa seja abrangente e represente
adequadamente os desafios e soluções reais enfrentados na integração de
agentes conversacionais avançados em sistemas complexos.</p>
<h3 id="conclusão-da-seleção-dos-materiais">Conclusão da Seleção dos
Materiais</h3>
<p>A seleção estratégica dos materiais e ferramentas utilizados neste
estudo não somente garante a qualidade científica e técnica dos
experimentos, mas também promove avanços significativos na interação
entre usuários e sistemas. Ao incorporar tecnologias reconhecidas pela
comunidade científica e pelo mercado, este estudo busca contribuir
ativamente para o desenvolvimento de soluções mais eficazes e
acessíveis, impactando positivamente a experiência do usuário em
diversas aplicações práticas.</p>
<h2 id="métodos">2.2 MÉTODOS</h2>
<p>Em métodos deve ter uma explicação minuciosa, detalhada, rigorosa e
exata de toda ação desenvolvida no método (caminho) do trabalho de
pesquisa. É necessário descrever quais equipamentos serão utilizados e
todo o procedimento experimental.</p>
<p>É a explicação do tipo de pesquisa, do instrumental utilizado
(softwares, equipamentos, questionários, entrevistas, etc.), do tempo
previsto, do laboratório, das formas de tabulação e tratamento dos
dados, enfim, de tudo aquilo que se utilizou ou será utilizado no
trabalho.</p>
<p><strong>A seguir regras de formatação para o desenvolvimento do
artigo:</strong></p>
<p>É de extrema importância realizar uma pesquisa bibliográfica, do tema
a ser estudado, baseada em periódicos nacionais e internacionais
(artigos, anais de congressos, revistas especializadas) e também em
livros, teses e dissertações para direcionar os procedimentos
experimentais adotados e os resultados e discussões obtidos. Essas
referências deveram ser citadas ao longo do artigo.</p>
<p>É importante compreender que cópias de trechos deverão ser feitas de
acordo com as normas da ABNT, ou seja: citações diretas e/ou indiretas,
curtas e/ou longas. Cópia de trechos e/ou na íntegra sem os devidos
créditos é considerado plágio (lei nº 9.610, de 19.02.98, que altera,
atualiza e consolida a legislação sobre direitos autorais). Não se
esqueça de nomear a seção.</p>
<h1 id="resultados-e-discussões">3 RESULTADOS E DISCUSSÕES</h1>
<p>Nos Resultados e Discussões, deve-se apresentar os resultados obtidos
no Procedimento Experimental e fazer uma discussão e análise sobre os
mesmos sempre que possível referenciando a literatura pesquisada.</p>
<h1 id="considerações-finais">4 CONSIDERAÇÕES FINAIS</h1>
<p>Etapa esta que servirá para você evidenciar as conquistas alcançadas
com o estudo e indicar as limitações e as reconsiderações. Além disso,
você poderá apontar a relação entre fatos verificados e teoria e mostrar
a contribuição da pesquisa para o meio acadêmico, empresarial e/ou para
o desenvolvimento da ciência e tecnologia. Além disso, você poderá
sugerir temas complementares a sua pesquisa para estudos futuros.
Responda aqui a sua pergunta-problema de pesquisa.</p>
<h1 id="referências">REFERÊNCIAS</h1>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Graduando em Engenharia de software no semestre letivo
de 2024-2. E-mail: castro.lucas290@gmail.com<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Professor do Centro Universitário UniSATC E-mail:
thyerri.mezzari@satc.edu.br<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
